{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `X_st` Sub-Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import label_binarize\n",
    "pd.set_option(\"display.max_columns\", 2000)\n",
    "pd.set_option(\"display.max_rows\", 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing `sklearn` packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Files\n",
    "\n",
    "- X = X_num\n",
    "- X_train = X_num_train\n",
    "- X_test = X_num_test\n",
    "- y\n",
    "- y_train\n",
    "- y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_pickle('Pickled_Files/X_st.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_text_0</th>\n",
       "      <th>short_text_1</th>\n",
       "      <th>short_text_2</th>\n",
       "      <th>short_text_3</th>\n",
       "      <th>short_text_4</th>\n",
       "      <th>short_text_5</th>\n",
       "      <th>short_text_6</th>\n",
       "      <th>short_text_7</th>\n",
       "      <th>short_text_8</th>\n",
       "      <th>short_text_9</th>\n",
       "      <th>short_text_10</th>\n",
       "      <th>short_text_11</th>\n",
       "      <th>short_text_12</th>\n",
       "      <th>short_text_13</th>\n",
       "      <th>short_text_14</th>\n",
       "      <th>short_text_15</th>\n",
       "      <th>short_text_16</th>\n",
       "      <th>short_text_17</th>\n",
       "      <th>short_text_18</th>\n",
       "      <th>short_text_19</th>\n",
       "      <th>short_text_20</th>\n",
       "      <th>short_text_21</th>\n",
       "      <th>short_text_22</th>\n",
       "      <th>short_text_23</th>\n",
       "      <th>short_text_24</th>\n",
       "      <th>short_text_25</th>\n",
       "      <th>short_text_26</th>\n",
       "      <th>short_text_27</th>\n",
       "      <th>short_text_28</th>\n",
       "      <th>short_text_29</th>\n",
       "      <th>short_text_30</th>\n",
       "      <th>short_text_31</th>\n",
       "      <th>short_text_32</th>\n",
       "      <th>short_text_33</th>\n",
       "      <th>short_text_34</th>\n",
       "      <th>short_text_35</th>\n",
       "      <th>short_text_36</th>\n",
       "      <th>short_text_37</th>\n",
       "      <th>short_text_38</th>\n",
       "      <th>short_text_39</th>\n",
       "      <th>short_text_40</th>\n",
       "      <th>short_text_41</th>\n",
       "      <th>short_text_42</th>\n",
       "      <th>short_text_43</th>\n",
       "      <th>short_text_44</th>\n",
       "      <th>short_text_45</th>\n",
       "      <th>short_text_46</th>\n",
       "      <th>short_text_47</th>\n",
       "      <th>short_text_48</th>\n",
       "      <th>short_text_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.440170e-27</td>\n",
       "      <td>-1.690746e-13</td>\n",
       "      <td>9.308252e-15</td>\n",
       "      <td>5.740873e-14</td>\n",
       "      <td>-1.874001e-14</td>\n",
       "      <td>-1.050953e-14</td>\n",
       "      <td>4.463773e-14</td>\n",
       "      <td>-2.480075e-14</td>\n",
       "      <td>2.689303e-14</td>\n",
       "      <td>-3.346194e-15</td>\n",
       "      <td>3.982091e-14</td>\n",
       "      <td>1.730784e-14</td>\n",
       "      <td>1.017644e-14</td>\n",
       "      <td>-1.441975e-15</td>\n",
       "      <td>-5.921199e-15</td>\n",
       "      <td>1.440689e-14</td>\n",
       "      <td>-2.474068e-15</td>\n",
       "      <td>1.778371e-15</td>\n",
       "      <td>-2.775338e-15</td>\n",
       "      <td>3.625112e-15</td>\n",
       "      <td>3.964154e-15</td>\n",
       "      <td>9.272003e-15</td>\n",
       "      <td>-1.123541e-14</td>\n",
       "      <td>-6.625697e-15</td>\n",
       "      <td>-2.749079e-15</td>\n",
       "      <td>1.368718e-14</td>\n",
       "      <td>-7.719601e-15</td>\n",
       "      <td>-1.788979e-14</td>\n",
       "      <td>-2.054853e-14</td>\n",
       "      <td>2.065982e-14</td>\n",
       "      <td>1.130244e-14</td>\n",
       "      <td>2.778331e-16</td>\n",
       "      <td>-2.484976e-15</td>\n",
       "      <td>-1.244665e-14</td>\n",
       "      <td>2.771972e-15</td>\n",
       "      <td>-3.294390e-15</td>\n",
       "      <td>2.192176e-14</td>\n",
       "      <td>1.886613e-14</td>\n",
       "      <td>6.073465e-15</td>\n",
       "      <td>-3.610103e-15</td>\n",
       "      <td>-8.461154e-15</td>\n",
       "      <td>-6.255754e-15</td>\n",
       "      <td>2.266018e-15</td>\n",
       "      <td>2.756950e-15</td>\n",
       "      <td>-1.001869e-14</td>\n",
       "      <td>2.982176e-15</td>\n",
       "      <td>-7.066037e-16</td>\n",
       "      <td>-3.498917e-15</td>\n",
       "      <td>1.181955e-16</td>\n",
       "      <td>-5.398560e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.231330e-28</td>\n",
       "      <td>1.744361e-26</td>\n",
       "      <td>-4.132407e-13</td>\n",
       "      <td>-4.818781e-13</td>\n",
       "      <td>3.098373e-13</td>\n",
       "      <td>7.621940e-14</td>\n",
       "      <td>3.249302e-13</td>\n",
       "      <td>-1.271755e-13</td>\n",
       "      <td>-6.391829e-14</td>\n",
       "      <td>1.296345e-13</td>\n",
       "      <td>4.261786e-14</td>\n",
       "      <td>-7.165265e-15</td>\n",
       "      <td>1.855603e-14</td>\n",
       "      <td>8.530088e-15</td>\n",
       "      <td>5.213153e-15</td>\n",
       "      <td>-2.465727e-14</td>\n",
       "      <td>-2.148211e-15</td>\n",
       "      <td>5.056668e-15</td>\n",
       "      <td>1.587892e-14</td>\n",
       "      <td>8.653523e-14</td>\n",
       "      <td>-8.477313e-14</td>\n",
       "      <td>1.234425e-15</td>\n",
       "      <td>-3.974781e-15</td>\n",
       "      <td>1.487708e-14</td>\n",
       "      <td>4.726819e-14</td>\n",
       "      <td>2.344170e-14</td>\n",
       "      <td>-1.074677e-13</td>\n",
       "      <td>7.636695e-14</td>\n",
       "      <td>1.708907e-14</td>\n",
       "      <td>6.912189e-16</td>\n",
       "      <td>1.934557e-14</td>\n",
       "      <td>-1.894538e-14</td>\n",
       "      <td>4.373940e-15</td>\n",
       "      <td>3.243805e-14</td>\n",
       "      <td>-4.811115e-15</td>\n",
       "      <td>4.052264e-15</td>\n",
       "      <td>-7.706880e-14</td>\n",
       "      <td>-3.615172e-14</td>\n",
       "      <td>-1.546684e-14</td>\n",
       "      <td>7.957497e-15</td>\n",
       "      <td>2.238576e-15</td>\n",
       "      <td>1.091473e-14</td>\n",
       "      <td>-1.923390e-15</td>\n",
       "      <td>-5.965659e-15</td>\n",
       "      <td>-2.593239e-15</td>\n",
       "      <td>-1.081106e-14</td>\n",
       "      <td>8.744866e-14</td>\n",
       "      <td>-4.795564e-15</td>\n",
       "      <td>2.472126e-14</td>\n",
       "      <td>7.119829e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   short_text_0  short_text_1  short_text_2  short_text_3  short_text_4  \\\n",
       "0  6.440170e-27 -1.690746e-13  9.308252e-15  5.740873e-14 -1.874001e-14   \n",
       "1 -1.231330e-28  1.744361e-26 -4.132407e-13 -4.818781e-13  3.098373e-13   \n",
       "\n",
       "   short_text_5  short_text_6  short_text_7  short_text_8  short_text_9  \\\n",
       "0 -1.050953e-14  4.463773e-14 -2.480075e-14  2.689303e-14 -3.346194e-15   \n",
       "1  7.621940e-14  3.249302e-13 -1.271755e-13 -6.391829e-14  1.296345e-13   \n",
       "\n",
       "   short_text_10  short_text_11  short_text_12  short_text_13  short_text_14  \\\n",
       "0   3.982091e-14   1.730784e-14   1.017644e-14  -1.441975e-15  -5.921199e-15   \n",
       "1   4.261786e-14  -7.165265e-15   1.855603e-14   8.530088e-15   5.213153e-15   \n",
       "\n",
       "   short_text_15  short_text_16  short_text_17  short_text_18  short_text_19  \\\n",
       "0   1.440689e-14  -2.474068e-15   1.778371e-15  -2.775338e-15   3.625112e-15   \n",
       "1  -2.465727e-14  -2.148211e-15   5.056668e-15   1.587892e-14   8.653523e-14   \n",
       "\n",
       "   short_text_20  short_text_21  short_text_22  short_text_23  short_text_24  \\\n",
       "0   3.964154e-15   9.272003e-15  -1.123541e-14  -6.625697e-15  -2.749079e-15   \n",
       "1  -8.477313e-14   1.234425e-15  -3.974781e-15   1.487708e-14   4.726819e-14   \n",
       "\n",
       "   short_text_25  short_text_26  short_text_27  short_text_28  short_text_29  \\\n",
       "0   1.368718e-14  -7.719601e-15  -1.788979e-14  -2.054853e-14   2.065982e-14   \n",
       "1   2.344170e-14  -1.074677e-13   7.636695e-14   1.708907e-14   6.912189e-16   \n",
       "\n",
       "   short_text_30  short_text_31  short_text_32  short_text_33  short_text_34  \\\n",
       "0   1.130244e-14   2.778331e-16  -2.484976e-15  -1.244665e-14   2.771972e-15   \n",
       "1   1.934557e-14  -1.894538e-14   4.373940e-15   3.243805e-14  -4.811115e-15   \n",
       "\n",
       "   short_text_35  short_text_36  short_text_37  short_text_38  short_text_39  \\\n",
       "0  -3.294390e-15   2.192176e-14   1.886613e-14   6.073465e-15  -3.610103e-15   \n",
       "1   4.052264e-15  -7.706880e-14  -3.615172e-14  -1.546684e-14   7.957497e-15   \n",
       "\n",
       "   short_text_40  short_text_41  short_text_42  short_text_43  short_text_44  \\\n",
       "0  -8.461154e-15  -6.255754e-15   2.266018e-15   2.756950e-15  -1.001869e-14   \n",
       "1   2.238576e-15   1.091473e-14  -1.923390e-15  -5.965659e-15  -2.593239e-15   \n",
       "\n",
       "   short_text_45  short_text_46  short_text_47  short_text_48  short_text_49  \n",
       "0   2.982176e-15  -7.066037e-16  -3.498917e-15   1.181955e-16  -5.398560e-16  \n",
       "1  -1.081106e-14   8.744866e-14  -4.795564e-15   2.472126e-14   7.119829e-16  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('Pickled_Files/X_st_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_text_0</th>\n",
       "      <th>short_text_1</th>\n",
       "      <th>short_text_2</th>\n",
       "      <th>short_text_3</th>\n",
       "      <th>short_text_4</th>\n",
       "      <th>short_text_5</th>\n",
       "      <th>short_text_6</th>\n",
       "      <th>short_text_7</th>\n",
       "      <th>short_text_8</th>\n",
       "      <th>short_text_9</th>\n",
       "      <th>short_text_10</th>\n",
       "      <th>short_text_11</th>\n",
       "      <th>short_text_12</th>\n",
       "      <th>short_text_13</th>\n",
       "      <th>short_text_14</th>\n",
       "      <th>short_text_15</th>\n",
       "      <th>short_text_16</th>\n",
       "      <th>short_text_17</th>\n",
       "      <th>short_text_18</th>\n",
       "      <th>short_text_19</th>\n",
       "      <th>short_text_20</th>\n",
       "      <th>short_text_21</th>\n",
       "      <th>short_text_22</th>\n",
       "      <th>short_text_23</th>\n",
       "      <th>short_text_24</th>\n",
       "      <th>short_text_25</th>\n",
       "      <th>short_text_26</th>\n",
       "      <th>short_text_27</th>\n",
       "      <th>short_text_28</th>\n",
       "      <th>short_text_29</th>\n",
       "      <th>short_text_30</th>\n",
       "      <th>short_text_31</th>\n",
       "      <th>short_text_32</th>\n",
       "      <th>short_text_33</th>\n",
       "      <th>short_text_34</th>\n",
       "      <th>short_text_35</th>\n",
       "      <th>short_text_36</th>\n",
       "      <th>short_text_37</th>\n",
       "      <th>short_text_38</th>\n",
       "      <th>short_text_39</th>\n",
       "      <th>short_text_40</th>\n",
       "      <th>short_text_41</th>\n",
       "      <th>short_text_42</th>\n",
       "      <th>short_text_43</th>\n",
       "      <th>short_text_44</th>\n",
       "      <th>short_text_45</th>\n",
       "      <th>short_text_46</th>\n",
       "      <th>short_text_47</th>\n",
       "      <th>short_text_48</th>\n",
       "      <th>short_text_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28154</th>\n",
       "      <td>0.194199</td>\n",
       "      <td>0.570411</td>\n",
       "      <td>0.063340</td>\n",
       "      <td>0.543272</td>\n",
       "      <td>0.084996</td>\n",
       "      <td>-0.027935</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>-0.027263</td>\n",
       "      <td>-0.051796</td>\n",
       "      <td>0.342298</td>\n",
       "      <td>0.126384</td>\n",
       "      <td>-0.013667</td>\n",
       "      <td>-0.375504</td>\n",
       "      <td>-0.038021</td>\n",
       "      <td>-0.060160</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.151047</td>\n",
       "      <td>-0.054186</td>\n",
       "      <td>-0.130252</td>\n",
       "      <td>0.053301</td>\n",
       "      <td>-0.026332</td>\n",
       "      <td>-0.007513</td>\n",
       "      <td>-0.021058</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>-0.003218</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>-0.001565</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>-0.000975</td>\n",
       "      <td>-0.003645</td>\n",
       "      <td>-0.003123</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.001429</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.001853</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>0.001845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6321</th>\n",
       "      <td>0.056340</td>\n",
       "      <td>0.152072</td>\n",
       "      <td>-0.163111</td>\n",
       "      <td>-0.144754</td>\n",
       "      <td>-0.042985</td>\n",
       "      <td>-0.008340</td>\n",
       "      <td>-0.333014</td>\n",
       "      <td>0.173051</td>\n",
       "      <td>-0.089876</td>\n",
       "      <td>0.031552</td>\n",
       "      <td>-0.199014</td>\n",
       "      <td>-0.007813</td>\n",
       "      <td>-0.031725</td>\n",
       "      <td>-0.008486</td>\n",
       "      <td>0.055478</td>\n",
       "      <td>-0.083462</td>\n",
       "      <td>-0.016289</td>\n",
       "      <td>-0.006124</td>\n",
       "      <td>0.066976</td>\n",
       "      <td>0.321831</td>\n",
       "      <td>0.235994</td>\n",
       "      <td>0.157966</td>\n",
       "      <td>-0.081791</td>\n",
       "      <td>-0.172525</td>\n",
       "      <td>-0.059484</td>\n",
       "      <td>0.166368</td>\n",
       "      <td>-0.223241</td>\n",
       "      <td>-0.301789</td>\n",
       "      <td>-0.027366</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>-0.045112</td>\n",
       "      <td>-0.104320</td>\n",
       "      <td>-0.003178</td>\n",
       "      <td>-0.015613</td>\n",
       "      <td>-0.001755</td>\n",
       "      <td>0.076650</td>\n",
       "      <td>-0.010941</td>\n",
       "      <td>0.020830</td>\n",
       "      <td>-0.052558</td>\n",
       "      <td>-0.146463</td>\n",
       "      <td>-0.203548</td>\n",
       "      <td>-0.011777</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.021224</td>\n",
       "      <td>-0.008569</td>\n",
       "      <td>-0.000949</td>\n",
       "      <td>-0.009463</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       short_text_0  short_text_1  short_text_2  short_text_3  short_text_4  \\\n",
       "28154      0.194199      0.570411      0.063340      0.543272      0.084996   \n",
       "6321       0.056340      0.152072     -0.163111     -0.144754     -0.042985   \n",
       "\n",
       "       short_text_5  short_text_6  short_text_7  short_text_8  short_text_9  \\\n",
       "28154     -0.027935      0.002018     -0.027263     -0.051796      0.342298   \n",
       "6321      -0.008340     -0.333014      0.173051     -0.089876      0.031552   \n",
       "\n",
       "       short_text_10  short_text_11  short_text_12  short_text_13  \\\n",
       "28154       0.126384      -0.013667      -0.375504      -0.038021   \n",
       "6321       -0.199014      -0.007813      -0.031725      -0.008486   \n",
       "\n",
       "       short_text_14  short_text_15  short_text_16  short_text_17  \\\n",
       "28154      -0.060160       0.003351       0.151047      -0.054186   \n",
       "6321        0.055478      -0.083462      -0.016289      -0.006124   \n",
       "\n",
       "       short_text_18  short_text_19  short_text_20  short_text_21  \\\n",
       "28154      -0.130252       0.053301      -0.026332      -0.007513   \n",
       "6321        0.066976       0.321831       0.235994       0.157966   \n",
       "\n",
       "       short_text_22  short_text_23  short_text_24  short_text_25  \\\n",
       "28154      -0.021058       0.006983       0.003423       0.001799   \n",
       "6321       -0.081791      -0.172525      -0.059484       0.166368   \n",
       "\n",
       "       short_text_26  short_text_27  short_text_28  short_text_29  \\\n",
       "28154      -0.001304      -0.003218       0.000893      -0.001565   \n",
       "6321       -0.223241      -0.301789      -0.027366      -0.071836   \n",
       "\n",
       "       short_text_30  short_text_31  short_text_32  short_text_33  \\\n",
       "28154      -0.001061       0.000751      -0.000975      -0.003645   \n",
       "6321       -0.045112      -0.104320      -0.003178      -0.015613   \n",
       "\n",
       "       short_text_34  short_text_35  short_text_36  short_text_37  \\\n",
       "28154      -0.003123      -0.000141       0.004526       0.004454   \n",
       "6321       -0.001755       0.076650      -0.010941       0.020830   \n",
       "\n",
       "       short_text_38  short_text_39  short_text_40  short_text_41  \\\n",
       "28154       0.002067      -0.000527      -0.000714      -0.001429   \n",
       "6321       -0.052558      -0.146463      -0.203548      -0.011777   \n",
       "\n",
       "       short_text_42  short_text_43  short_text_44  short_text_45  \\\n",
       "28154       0.001066       0.001150       0.000146      -0.000059   \n",
       "6321        0.002141       0.000119       0.021224      -0.008569   \n",
       "\n",
       "       short_text_46  short_text_47  short_text_48  short_text_49  \n",
       "28154      -0.001853       0.000111      -0.001252       0.001845  \n",
       "6321       -0.000949      -0.009463      -0.000478       0.001415  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39481, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_pickle('Pickled_Files/X_st_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_text_0</th>\n",
       "      <th>short_text_1</th>\n",
       "      <th>short_text_2</th>\n",
       "      <th>short_text_3</th>\n",
       "      <th>short_text_4</th>\n",
       "      <th>short_text_5</th>\n",
       "      <th>short_text_6</th>\n",
       "      <th>short_text_7</th>\n",
       "      <th>short_text_8</th>\n",
       "      <th>short_text_9</th>\n",
       "      <th>short_text_10</th>\n",
       "      <th>short_text_11</th>\n",
       "      <th>short_text_12</th>\n",
       "      <th>short_text_13</th>\n",
       "      <th>short_text_14</th>\n",
       "      <th>short_text_15</th>\n",
       "      <th>short_text_16</th>\n",
       "      <th>short_text_17</th>\n",
       "      <th>short_text_18</th>\n",
       "      <th>short_text_19</th>\n",
       "      <th>short_text_20</th>\n",
       "      <th>short_text_21</th>\n",
       "      <th>short_text_22</th>\n",
       "      <th>short_text_23</th>\n",
       "      <th>short_text_24</th>\n",
       "      <th>short_text_25</th>\n",
       "      <th>short_text_26</th>\n",
       "      <th>short_text_27</th>\n",
       "      <th>short_text_28</th>\n",
       "      <th>short_text_29</th>\n",
       "      <th>short_text_30</th>\n",
       "      <th>short_text_31</th>\n",
       "      <th>short_text_32</th>\n",
       "      <th>short_text_33</th>\n",
       "      <th>short_text_34</th>\n",
       "      <th>short_text_35</th>\n",
       "      <th>short_text_36</th>\n",
       "      <th>short_text_37</th>\n",
       "      <th>short_text_38</th>\n",
       "      <th>short_text_39</th>\n",
       "      <th>short_text_40</th>\n",
       "      <th>short_text_41</th>\n",
       "      <th>short_text_42</th>\n",
       "      <th>short_text_43</th>\n",
       "      <th>short_text_44</th>\n",
       "      <th>short_text_45</th>\n",
       "      <th>short_text_46</th>\n",
       "      <th>short_text_47</th>\n",
       "      <th>short_text_48</th>\n",
       "      <th>short_text_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25981</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48891</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       short_text_0  short_text_1  short_text_2  short_text_3  short_text_4  \\\n",
       "25981           0.0          -0.0           0.0          -0.0           0.0   \n",
       "48891           0.0          -0.0           0.0          -0.0           0.0   \n",
       "\n",
       "       short_text_5  short_text_6  short_text_7  short_text_8  short_text_9  \\\n",
       "25981          -0.0           0.0           0.0          -0.0           0.0   \n",
       "48891          -0.0           0.0           0.0          -0.0           0.0   \n",
       "\n",
       "       short_text_10  short_text_11  short_text_12  short_text_13  \\\n",
       "25981           -0.0            0.0           -0.0           -0.0   \n",
       "48891           -0.0            0.0           -0.0           -0.0   \n",
       "\n",
       "       short_text_14  short_text_15  short_text_16  short_text_17  \\\n",
       "25981           -0.0            0.0           -0.0           -0.0   \n",
       "48891           -0.0            0.0           -0.0           -0.0   \n",
       "\n",
       "       short_text_18  short_text_19  short_text_20  short_text_21  \\\n",
       "25981           -0.0            0.0            0.0           -0.0   \n",
       "48891           -0.0            0.0            0.0           -0.0   \n",
       "\n",
       "       short_text_22  short_text_23  short_text_24  short_text_25  \\\n",
       "25981           -0.0           -0.0            0.0            0.0   \n",
       "48891           -0.0           -0.0            0.0            0.0   \n",
       "\n",
       "       short_text_26  short_text_27  short_text_28  short_text_29  \\\n",
       "25981            0.0           -0.0           -0.0           -0.0   \n",
       "48891            0.0           -0.0           -0.0           -0.0   \n",
       "\n",
       "       short_text_30  short_text_31  short_text_32  short_text_33  \\\n",
       "25981            0.0           -0.0            0.0            0.0   \n",
       "48891            0.0           -0.0            0.0            0.0   \n",
       "\n",
       "       short_text_34  short_text_35  short_text_36  short_text_37  \\\n",
       "25981            0.0           -0.0           -0.0            0.0   \n",
       "48891            0.0           -0.0           -0.0            0.0   \n",
       "\n",
       "       short_text_38  short_text_39  short_text_40  short_text_41  \\\n",
       "25981            0.0           -0.0           -0.0           -0.0   \n",
       "48891            0.0           -0.0           -0.0           -0.0   \n",
       "\n",
       "       short_text_42  short_text_43  short_text_44  short_text_45  \\\n",
       "25981           -0.0           -0.0           -0.0           -0.0   \n",
       "48891           -0.0           -0.0           -0.0           -0.0   \n",
       "\n",
       "       short_text_46  short_text_47  short_text_48  short_text_49  \n",
       "25981            0.0            0.0           -0.0           -0.0  \n",
       "48891            0.0            0.0           -0.0           -0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9871, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.load('Pickled_Files/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 1, ..., 2, 1, 1]), (49352,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.load('Pickled_Files/y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 2, ..., 0, 1, 1]), (39481,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = np.load('Pickled_Files/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, ..., 2, 2, 1]), (9871,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ensemble Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    \n",
    "    y_hat = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_hat_proba = model.predict_proba(X_train)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    return {'model': model,\n",
    "            'X': X,\n",
    "            'X_test': X_test,\n",
    "            'X_train': X_train,\n",
    "            'y': y,\n",
    "            'y_test': y_test,\n",
    "            'y_train': y_train,\n",
    "            'y_hat': y_hat,\n",
    "            'y_pred': y_pred,\n",
    "            'y_hat_proba': y_hat_proba,\n",
    "            'y_pred_proba': y_pred_proba,\n",
    "            'train_score': train_score,\n",
    "            'test_score': test_score\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_summary(model, data_dictionary):\n",
    "    \n",
    "    class_rpt = classification_report(data_dictionary['y_test'], data_dictionary['y_pred'])\n",
    "    log_loss_score_train = log_loss(data_dictionary['y_train'], data_dictionary['y_hat_proba'])\n",
    "    log_loss_score_test = log_loss(data_dictionary['y_test'], data_dictionary['y_pred_proba'])\n",
    "    \n",
    "    print (\"Model Summary Report:\\n\")\n",
    "    print (model)\n",
    "    print (\"\\n\")\n",
    "    print (\"Classification Report:\\n\")\n",
    "    print (class_rpt)\n",
    "    print (\"Accuracy on training set: {:4f}\".format(model.score(data_dictionary['X_train'], \n",
    "                                                                data_dictionary['y_train'])))\n",
    "    \n",
    "    print (\"Accuracy on test set:     {:4f}\".format(model.score(data_dictionary['X_test'], \n",
    "                                                            data_dictionary['y_test'])))\n",
    "    print (\"\\n\")\n",
    "    print (\"Log Loss on training set: {:4f}\".format(log_loss_score_train))\n",
    "    print (\"Log Loss on test set:     {:4f}\".format(log_loss_score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "\n",
    "class MajorityVoteClassifier(BaseEstimator, \n",
    "                             ClassifierMixin):\n",
    "    \"\"\" A majority vote ensemble classifier\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    classifiers : array-like, shape = [n_classifiers]\n",
    "      Different classifiers for the ensemble\n",
    "\n",
    "    vote : str, {'classlabel', 'probability'} (default='label')\n",
    "      If 'classlabel' the prediction is based on the argmax of\n",
    "        class labels. Else if 'probability', the argmax of\n",
    "        the sum of probabilities is used to predict the class label\n",
    "        (recommended for calibrated classifiers).\n",
    "\n",
    "    weights : array-like, shape = [n_classifiers], optional (default=None)\n",
    "      If a list of `int` or `float` values are provided, the classifiers\n",
    "      are weighted by importance; Uses uniform weights if `weights=None`.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, classifiers, vote='classlabel', weights=None):\n",
    "\n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers = {key: value for key, value\n",
    "                                  in _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit classifiers.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Matrix of training samples.\n",
    "\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Vector of target class labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        if self.vote not in ('probability', 'classlabel'):\n",
    "            raise ValueError(\"vote must be 'probability' or 'classlabel'\"\n",
    "                             \"; got (vote=%r)\"\n",
    "                             % self.vote)\n",
    "\n",
    "        if self.weights and len(self.weights) != len(self.classifiers):\n",
    "            raise ValueError('Number of classifiers and weights must be equal'\n",
    "                             '; got %d weights, %d classifiers'\n",
    "                             % (len(self.weights), len(self.classifiers)))\n",
    "\n",
    "        # Use LabelEncoder to ensure class labels start with 0, which\n",
    "        # is important for np.argmax call in self.predict\n",
    "        self.lablenc_ = LabelEncoder()\n",
    "        self.lablenc_.fit(y)\n",
    "        self.classes_ = self.lablenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X, self.lablenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict class labels for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Matrix of training samples.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        maj_vote : array-like, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "            \n",
    "        \"\"\"\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X), axis=1)\n",
    "        else:  # 'classlabel' vote\n",
    "\n",
    "            #  Collect results from clf.predict calls\n",
    "            predictions = np.asarray([clf.predict(X)\n",
    "                                      for clf in self.classifiers_]).T\n",
    "\n",
    "            maj_vote = np.apply_along_axis(\n",
    "                                      lambda x:\n",
    "                                      np.argmax(np.bincount(x,\n",
    "                                                weights=self.weights)),\n",
    "                                      axis=1,\n",
    "                                      arr=predictions)\n",
    "        maj_vote = self.lablenc_.inverse_transform(maj_vote)\n",
    "        return maj_vote\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\" Predict class probabilities for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        avg_proba : array-like, shape = [n_samples, n_classes]\n",
    "            Weighted average probability for each class per sample.\n",
    "\n",
    "        \"\"\"\n",
    "        probas = np.asarray([clf.predict_proba(X)\n",
    "                             for clf in self.classifiers_])\n",
    "        avg_proba = np.average(probas, axis=0, weights=self.weights)\n",
    "        return avg_proba\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\" Get classifier parameter names for GridSearch\"\"\"\n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier, self).get_params(deep=False)\n",
    "        else:\n",
    "            out = self.named_classifiers.copy()\n",
    "            for name, step in six.iteritems(self.named_classifiers):\n",
    "                for key, value in six.iteritems(step.get_params(deep=True)):\n",
    "                    out['%s__%s' % (name, key)] = value\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing a global dictionary to store the various models for later retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_num_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `X_st` Sub-Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Logistic Regression w/Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(penalty='l2',\n",
    "                          C=0.001,\n",
    "                          n_jobs=-1,\n",
    "                          random_state=82\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_num_clf1_dictionary = evaluate_model(clf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary Report:\n",
      "\n",
      "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=82, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       775\n",
      "          1       0.69      1.00      0.82      6834\n",
      "          2       0.00      0.00      0.00      2262\n",
      "\n",
      "avg / total       0.48      0.69      0.57      9871\n",
      "\n",
      "Accuracy on training set: 0.695271\n",
      "Accuracy on test set:     0.692331\n",
      "\n",
      "\n",
      "Log Loss on training set: 0.798373\n",
      "Log Loss on test set:     0.801760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nate_velarde/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model_summary(clf1, X_num_clf1_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Model 1 via GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "          'penalty': ['l2']\n",
    "         }\n",
    "\n",
    "gs_clf1 = GridSearchCV(clf1,\n",
    "                       params, \n",
    "                       n_jobs=-1,\n",
    "                       cv=10,\n",
    "                       verbose=1\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 7 candidates, totalling 70 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:   20.0s finished\n"
     ]
    }
   ],
   "source": [
    "X_num_gs_clf1_dictionary = evaluate_model(gs_clf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary Report:\n",
      "\n",
      "GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=82, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=-1,\n",
      "       param_grid={'penalty': ['l2'], 'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=1)\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       775\n",
      "          1       0.69      1.00      0.82      6834\n",
      "          2       0.00      0.00      0.00      2262\n",
      "\n",
      "avg / total       0.48      0.69      0.57      9871\n",
      "\n",
      "Accuracy on training set: 0.695271\n",
      "Accuracy on test set:     0.692331\n",
      "\n",
      "\n",
      "Log Loss on training set: 0.907944\n",
      "Log Loss on test set:     0.909469\n"
     ]
    }
   ],
   "source": [
    "model_summary(gs_clf1, X_num_gs_clf1_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_num_models['gs_clf1'] = {'model': gs_clf1.best_estimator_,\n",
    "                           'best_params': gs_clf1.best_params_,\n",
    "                           'score': gs_clf1.best_score_\n",
    "                          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'C': 0.0001, 'penalty': 'l2'},\n",
       " 'model': LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=-1, penalty='l2', random_state=82,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       " 'score': 0.69527114308148219}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_models['gs_clf1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pickled_Files/X_st_Sub_Models/X_st_gs_clf1.pickle']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gs_clf1, 'Pickled_Files/X_st_Sub_Models/X_st_gs_clf1.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model 2 - Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf2 = DecisionTreeClassifier(max_depth=2,\n",
    "                              criterion='entropy',\n",
    "                              random_state=82\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_num_clf2_dictionary = evaluate_model(clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary Report:\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=82, splitter='best')\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       775\n",
      "          1       0.69      1.00      0.82      6834\n",
      "          2       0.00      0.00      0.00      2262\n",
      "\n",
      "avg / total       0.48      0.69      0.57      9871\n",
      "\n",
      "Accuracy on training set: 0.695271\n",
      "Accuracy on test set:     0.692331\n",
      "\n",
      "\n",
      "Log Loss on training set: 0.787219\n",
      "Log Loss on test set:     0.792642\n"
     ]
    }
   ],
   "source": [
    "model_summary(clf2, X_num_clf2_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Model 2 via GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'splitter': ['best', 'random'],\n",
    "          'max_depth': [1, 3, 5],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "gs_clf2 = GridSearchCV(clf2,\n",
    "                       params, \n",
    "                       n_jobs=-1,\n",
    "                       cv=10,\n",
    "                       verbose=1\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:   41.9s finished\n"
     ]
    }
   ],
   "source": [
    "X_num_gs_clf2_dictionary = evaluate_model(gs_clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary Report:\n",
      "\n",
      "GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=82, splitter='best'),\n",
      "       fit_params={}, iid=True, n_jobs=-1,\n",
      "       param_grid={'min_samples_split': [2, 5], 'splitter': ['best', 'random'], 'criterion': ['gini', 'entropy'], 'max_depth': [1, 3, 5], 'min_samples_leaf': [1, 2, 3]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=1)\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       775\n",
      "          1       0.69      1.00      0.82      6834\n",
      "          2       0.00      0.00      0.00      2262\n",
      "\n",
      "avg / total       0.48      0.69      0.57      9871\n",
      "\n",
      "Accuracy on training set: 0.695271\n",
      "Accuracy on test set:     0.692331\n",
      "\n",
      "\n",
      "Log Loss on training set: 0.787570\n",
      "Log Loss on test set:     0.792128\n"
     ]
    }
   ],
   "source": [
    "model_summary(gs_clf2, X_num_gs_clf2_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_num_models['gs_clf2'] = {'model': gs_clf2.best_estimator_,\n",
    "                           'best_params': gs_clf2.best_params_,\n",
    "                           'score': gs_clf2.best_score_\n",
    "                          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'criterion': 'gini',\n",
       "  'max_depth': 1,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 2,\n",
       "  'splitter': 'best'},\n",
       " 'model': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             presort=False, random_state=82, splitter='best'),\n",
       " 'score': 0.69527114308148219}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_models['gs_clf2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pickled_Files/X_st_Sub_Models/X_st_gs_clf2.pickle']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gs_clf2, 'Pickled_Files/X_st_Sub_Models/X_st_gs_clf2.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf3 = GradientBoostingClassifier(max_depth=1,\n",
    "                                  learning_rate=0.01,\n",
    "                                  random_state=82\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_num_clf3_dictionary = evaluate_model(clf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary Report:\n",
      "\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.01, loss='deviance', max_depth=1,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=82,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       775\n",
      "          1       0.69      1.00      0.82      6834\n",
      "          2       0.00      0.00      0.00      2262\n",
      "\n",
      "avg / total       0.48      0.69      0.57      9871\n",
      "\n",
      "Accuracy on training set: 0.695271\n",
      "Accuracy on test set:     0.692331\n",
      "\n",
      "\n",
      "Log Loss on training set: 0.809625\n",
      "Log Loss on test set:     0.813259\n"
     ]
    }
   ],
   "source": [
    "model_summary(clf3, X_num_clf3_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Model 3 via GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'max_depth': [1, 3],\n",
    "          'learning_rate': [0.01, 0.10, 1.0]\n",
    "         }\n",
    "\n",
    "gs_clf3 = GridSearchCV(clf3,\n",
    "                       params, \n",
    "                       n_jobs=-1,\n",
    "                       cv=10,\n",
    "                       verbose=1\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  7.5min finished\n"
     ]
    }
   ],
   "source": [
    "X_num_gs_clf3_dictionary = evaluate_model(gs_clf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary Report:\n",
      "\n",
      "GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.01, loss='deviance', max_depth=1,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=82,\n",
      "              subsample=1.0, verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=-1,\n",
      "       param_grid={'learning_rate': [0.01, 0.1, 1.0], 'max_depth': [1, 3]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=1)\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       775\n",
      "          1       0.69      1.00      0.82      6834\n",
      "          2       0.00      0.00      0.00      2262\n",
      "\n",
      "avg / total       0.48      0.69      0.57      9871\n",
      "\n",
      "Accuracy on training set: 0.695271\n",
      "Accuracy on test set:     0.692331\n",
      "\n",
      "\n",
      "Log Loss on training set: 0.809625\n",
      "Log Loss on test set:     0.813259\n"
     ]
    }
   ],
   "source": [
    "model_summary(gs_clf3, X_num_gs_clf3_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_num_models['gs_clf3'] = {'model': gs_clf3.best_estimator_,\n",
    "                           'best_params': gs_clf3.best_params_,\n",
    "                           'score': gs_clf3.best_score_\n",
    "                          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_params': {'learning_rate': 0.01, 'max_depth': 1},\n",
       " 'model': GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "               learning_rate=0.01, loss='deviance', max_depth=1,\n",
       "               max_features=None, max_leaf_nodes=None,\n",
       "               min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "               min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "               n_estimators=100, presort='auto', random_state=82,\n",
       "               subsample=1.0, verbose=0, warm_start=False),\n",
       " 'score': 0.69524581444238998}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_models['gs_clf3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pickled_Files/X_st_Sub_Models/X_st_gs_clf3.pickle']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gs_clf3, 'Pickled_Files/X_st_Sub_Models/X_st_gs_clf3.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_labels = ['Logistic Regression', 'Decision Tree Classifier', 'Gradient Boosting Classifier']\n",
    "\n",
    "mv_clf = MajorityVoteClassifier(classifiers=[X_num_models['gs_clf1']['model'],\n",
    "                                             X_num_models['gs_clf2']['model'],\n",
    "                                             X_num_models['gs_clf3']['model']\n",
    "                                             ])\n",
    "\n",
    "clf_labels += ['Majority Voting']\n",
    "\n",
    "all_clf = [X_num_models['gs_clf1']['model'],\n",
    "            X_num_models['gs_clf2']['model'],\n",
    "            X_num_models['gs_clf3']['model'],\n",
    "            mv_clf\n",
    "          ]\n",
    "\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=5,\n",
    "                             scoring='accuracy')\n",
    "    \n",
    "    print(\"Accuracy: %0.4f (+/- %0.4f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_labels = ['Logistic Regression', 'Decision Tree Classifier', 'Gradient Boosting Classifier']\n",
    "\n",
    "mv_clf = MajorityVoteClassifier(classifiers=[X_num_models['gs_clf1']['model'],\n",
    "                                             X_num_models['gs_clf2']['model'],\n",
    "                                             X_num_models['gs_clf3']['model']\n",
    "                                             ])\n",
    "\n",
    "clf_labels += ['Majority Voting']\n",
    "\n",
    "all_clf = [X_num_models['gs_clf1']['model'],\n",
    "            X_num_models['gs_clf2']['model'],\n",
    "            X_num_models['gs_clf3']['model'],\n",
    "            mv_clf\n",
    "          ]\n",
    "\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=5,\n",
    "                             scoring='neg_log_loss')\n",
    "    \n",
    "    print(\"Negative Log Loss: %0.4f (+/- %0.4f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating Predicted Probabilities from Best Short-Term Text Sub-Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_text_predict_probs = gs_clf3.best_estimator_.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (49352, 3))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(short_text_predict_probs), short_text_predict_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST_High_Proba</th>\n",
       "      <th>ST_Low_Proba</th>\n",
       "      <th>ST_Medium_Proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.141227</td>\n",
       "      <td>0.622064</td>\n",
       "      <td>0.236709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.141610</td>\n",
       "      <td>0.621039</td>\n",
       "      <td>0.237351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.141227</td>\n",
       "      <td>0.622064</td>\n",
       "      <td>0.236709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.141285</td>\n",
       "      <td>0.623330</td>\n",
       "      <td>0.235384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.146010</td>\n",
       "      <td>0.609265</td>\n",
       "      <td>0.244726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.141610</td>\n",
       "      <td>0.621039</td>\n",
       "      <td>0.237351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.141610</td>\n",
       "      <td>0.621039</td>\n",
       "      <td>0.237351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.141610</td>\n",
       "      <td>0.621039</td>\n",
       "      <td>0.237351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.141610</td>\n",
       "      <td>0.621039</td>\n",
       "      <td>0.237351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.141610</td>\n",
       "      <td>0.621039</td>\n",
       "      <td>0.237351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.143439</td>\n",
       "      <td>0.629058</td>\n",
       "      <td>0.227503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.142453</td>\n",
       "      <td>0.618782</td>\n",
       "      <td>0.238765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.141227</td>\n",
       "      <td>0.622064</td>\n",
       "      <td>0.236709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.146516</td>\n",
       "      <td>0.607910</td>\n",
       "      <td>0.245574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.141610</td>\n",
       "      <td>0.621039</td>\n",
       "      <td>0.237351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.138765</td>\n",
       "      <td>0.629087</td>\n",
       "      <td>0.232148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.141610</td>\n",
       "      <td>0.621039</td>\n",
       "      <td>0.237351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.141610</td>\n",
       "      <td>0.621039</td>\n",
       "      <td>0.237351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.141610</td>\n",
       "      <td>0.621039</td>\n",
       "      <td>0.237351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.142453</td>\n",
       "      <td>0.618782</td>\n",
       "      <td>0.238765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.141752</td>\n",
       "      <td>0.620658</td>\n",
       "      <td>0.237590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.142111</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.238190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.141752</td>\n",
       "      <td>0.620658</td>\n",
       "      <td>0.237590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.142253</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.238429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.138281</td>\n",
       "      <td>0.629949</td>\n",
       "      <td>0.231771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ST_High_Proba  ST_Low_Proba  ST_Medium_Proba\n",
       "0        0.142253      0.619318         0.238429\n",
       "1        0.142253      0.619318         0.238429\n",
       "2        0.142253      0.619318         0.238429\n",
       "3        0.142253      0.619318         0.238429\n",
       "4        0.142253      0.619318         0.238429\n",
       "5        0.142253      0.619318         0.238429\n",
       "6        0.142111      0.619699         0.238190\n",
       "7        0.142253      0.619318         0.238429\n",
       "8        0.142253      0.619318         0.238429\n",
       "9        0.142253      0.619318         0.238429\n",
       "10       0.142253      0.619318         0.238429\n",
       "11       0.141227      0.622064         0.236709\n",
       "12       0.142253      0.619318         0.238429\n",
       "13       0.142111      0.619699         0.238190\n",
       "14       0.141610      0.621039         0.237351\n",
       "15       0.142253      0.619318         0.238429\n",
       "16       0.142253      0.619318         0.238429\n",
       "17       0.141227      0.622064         0.236709\n",
       "18       0.142253      0.619318         0.238429\n",
       "19       0.142253      0.619318         0.238429\n",
       "20       0.142253      0.619318         0.238429\n",
       "21       0.141285      0.623330         0.235384\n",
       "22       0.142253      0.619318         0.238429\n",
       "23       0.146010      0.609265         0.244726\n",
       "24       0.141610      0.621039         0.237351\n",
       "25       0.142253      0.619318         0.238429\n",
       "26       0.142253      0.619318         0.238429\n",
       "27       0.141610      0.621039         0.237351\n",
       "28       0.142253      0.619318         0.238429\n",
       "29       0.142253      0.619318         0.238429\n",
       "30       0.142111      0.619699         0.238190\n",
       "31       0.141610      0.621039         0.237351\n",
       "32       0.142253      0.619318         0.238429\n",
       "33       0.142253      0.619318         0.238429\n",
       "34       0.142253      0.619318         0.238429\n",
       "35       0.142111      0.619699         0.238190\n",
       "36       0.142111      0.619699         0.238190\n",
       "37       0.142253      0.619318         0.238429\n",
       "38       0.141610      0.621039         0.237351\n",
       "39       0.141610      0.621039         0.237351\n",
       "40       0.142253      0.619318         0.238429\n",
       "41       0.142111      0.619699         0.238190\n",
       "42       0.143439      0.629058         0.227503\n",
       "43       0.142253      0.619318         0.238429\n",
       "44       0.142253      0.619318         0.238429\n",
       "45       0.142253      0.619318         0.238429\n",
       "46       0.142253      0.619318         0.238429\n",
       "47       0.142453      0.618782         0.238765\n",
       "48       0.142253      0.619318         0.238429\n",
       "49       0.141227      0.622064         0.236709\n",
       "50       0.142253      0.619318         0.238429\n",
       "51       0.142253      0.619318         0.238429\n",
       "52       0.142253      0.619318         0.238429\n",
       "53       0.142111      0.619699         0.238190\n",
       "54       0.142253      0.619318         0.238429\n",
       "55       0.142253      0.619318         0.238429\n",
       "56       0.142253      0.619318         0.238429\n",
       "57       0.142253      0.619318         0.238429\n",
       "58       0.142111      0.619699         0.238190\n",
       "59       0.142253      0.619318         0.238429\n",
       "60       0.142253      0.619318         0.238429\n",
       "61       0.142253      0.619318         0.238429\n",
       "62       0.142253      0.619318         0.238429\n",
       "63       0.142253      0.619318         0.238429\n",
       "64       0.142253      0.619318         0.238429\n",
       "65       0.142253      0.619318         0.238429\n",
       "66       0.142253      0.619318         0.238429\n",
       "67       0.146516      0.607910         0.245574\n",
       "68       0.142253      0.619318         0.238429\n",
       "69       0.141610      0.621039         0.237351\n",
       "70       0.138765      0.629087         0.232148\n",
       "71       0.142253      0.619318         0.238429\n",
       "72       0.141610      0.621039         0.237351\n",
       "73       0.142111      0.619699         0.238190\n",
       "74       0.141610      0.621039         0.237351\n",
       "75       0.142253      0.619318         0.238429\n",
       "76       0.142111      0.619699         0.238190\n",
       "77       0.142111      0.619699         0.238190\n",
       "78       0.142253      0.619318         0.238429\n",
       "79       0.142253      0.619318         0.238429\n",
       "80       0.142253      0.619318         0.238429\n",
       "81       0.142111      0.619699         0.238190\n",
       "82       0.142253      0.619318         0.238429\n",
       "83       0.142253      0.619318         0.238429\n",
       "84       0.142253      0.619318         0.238429\n",
       "85       0.142253      0.619318         0.238429\n",
       "86       0.142253      0.619318         0.238429\n",
       "87       0.142253      0.619318         0.238429\n",
       "88       0.142253      0.619318         0.238429\n",
       "89       0.141610      0.621039         0.237351\n",
       "90       0.142253      0.619318         0.238429\n",
       "91       0.142111      0.619699         0.238190\n",
       "92       0.142453      0.618782         0.238765\n",
       "93       0.141752      0.620658         0.237590\n",
       "94       0.142111      0.619699         0.238190\n",
       "95       0.142253      0.619318         0.238429\n",
       "96       0.142253      0.619318         0.238429\n",
       "97       0.141752      0.620658         0.237590\n",
       "98       0.142253      0.619318         0.238429\n",
       "99       0.138281      0.629949         0.231771"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_text_ydf = pd.DataFrame(data=short_text_predict_probs, columns=['ST_High_Proba', \n",
    "                                                                      'ST_Low_Proba',\n",
    "                                                                      'ST_Medium_Proba'])\n",
    "\n",
    "short_text_ydf.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_text_ydf.to_pickle('Pickled_Files/X_st_proba.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Stacking Plan:\n",
    "\n",
    "- Merge X_st_proba and X_lt_proba to X_num \n",
    "- Test/Train/Split\n",
    "- Run through models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MISC NOTES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can call the model, `X_num_models['gs_clf1']['model']` - for use in majority voting below**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "X_num_models['gs_clf1']['model'].predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to Load in a Pickled Model**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from_pkl_cls = joblib.load(\"tnc_model.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
